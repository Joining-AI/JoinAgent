{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "服务初始化成功\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import threading\n",
    "from http.server import HTTPServer, SimpleHTTPRequestHandler\n",
    "from local_packages import *\n",
    "from dotenv import load_dotenv\n",
    "from queue import Queue\n",
    "import concurrent.futures\n",
    "import random\n",
    "import json\n",
    "import openai\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# 加载环境变量\n",
    "dotenv_path = os.path.join(os.getcwd(), '.env')\n",
    "\n",
    "# 设置项目根目录和图片目录\n",
    "project_root = os.path.dirname(dotenv_path)\n",
    "\n",
    "service_type = 'qwen'\n",
    "\n",
    "def initialize_service(service_type):\n",
    "    if service_type in ['zhipu', None]:\n",
    "        version = 'glm-3-turbo'\n",
    "        #'glm-4' 'glm-4v' 'glm-3-turbo'\n",
    "        service = GLMService(version)\n",
    "    elif service_type in ['qwen']:\n",
    "        version = 'long'\n",
    "        service=QwenService(version)\n",
    "    elif service_type in ['kimi']:\n",
    "        version = '8k'\n",
    "        #'8k'1M/12￥ '32k'1M/24￥ '128k'1M/60￥\n",
    "        service = KimiService(version)\n",
    "    elif service_type in ['sensetime']:\n",
    "        version = 'SenseChat'\n",
    "        #SenseChat SenseChat-32K SenseChat-128K SenseChat-Turbo SenseChat-FunctionCall\n",
    "        service = SenseService(version=version)\n",
    "    else:\n",
    "        raise ValueError('未知的服务类型')\n",
    "    \n",
    "    return service\n",
    "\n",
    "service = initialize_service(service_type)\n",
    "\n",
    "js=JSProcessor()\n",
    "\n",
    "class ParseError(Exception):\n",
    "    def __init__(self, code, message=\"解析失败\"):\n",
    "        self.code = code\n",
    "        self.message = message\n",
    "        super().__init__(self.message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 地址创建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有目录和文件已成功创建。\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 定义根文件夹和模型路径\n",
    "root_folder = 'Task1_xlsx_processor'\n",
    "model_path = r'D:\\Joining\\Models\\Text2Vec_base_zh'\n",
    "\n",
    "\n",
    "# 创建所有需要的目录\n",
    "directories = [\n",
    "    root_folder\n",
    "]\n",
    "\n",
    "for directory in directories:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "print(\"所有目录和文件已成功创建。\")\n",
    "\n",
    "xlsx_file_path = r\"D:\\Joining\\Joining-Agents0529\\大模型日报汇编-论文(1).xlsx\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xlsx转换成json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def xlsx_to_json(xlsx_file_path, json_file_path):\n",
    "    try:\n",
    "        # 读取 XLSX 文件\n",
    "        df = pd.read_excel(xlsx_file_path)\n",
    "        \n",
    "        # 将 DataFrame 转换为 JSON 格式\n",
    "        json_data = df.to_json(orient='records', force_ascii=False)\n",
    "        \n",
    "        # 将 JSON 数据写入文件\n",
    "        with open(json_file_path, 'w', encoding='utf-8') as json_file:\n",
    "            json_file.write(json_data)\n",
    "        \n",
    "        print(f\"成功将 {xlsx_file_path} 转换为 {json_file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"转换时发生错误: {e}\")\n",
    "\n",
    "# 示例用法\n",
    "json_file_path = r'D:\\Joining\\Joining-Agents0529\\Task23_xlsx_opener\\converted.json'\n",
    "xlsx_to_json(xlsx_file_path, json_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 添加标记符"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_recog_index_to_dict_list(json_file_path):\n",
    "    try:\n",
    "        # 读取 JSON 文件\n",
    "        with open(json_file_path, 'r', encoding='utf-8') as json_file:\n",
    "            dict_list = json.load(json_file)\n",
    "        \n",
    "        # 为每个字典添加 recog_index 键\n",
    "        for index, sub_dict in enumerate(dict_list):\n",
    "            sub_dict['recog_index'] = index\n",
    "        \n",
    "        # 将包含字典的列表转换为 JSON 格式\n",
    "        json_data = json.dumps(dict_list, ensure_ascii=False, indent=4)\n",
    "        \n",
    "        # 将 JSON 数据写入文件\n",
    "        with open(json_file_path, 'w', encoding='utf-8') as json_file:\n",
    "            json_file.write(json_data)\n",
    "        \n",
    "        print(f\"成功在 {json_file_path} 中添加 recog_index\")\n",
    "    except Exception as e:\n",
    "        print(f\"添加 recog_index 时发生错误: {e}\")\n",
    "        \n",
    "add_recog_index_to_dict_list(json_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 处理json\n",
    "读出list的sub_dict中所有value为null的key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_list=js.read_json(r'D:\\Joining\\Joining-Agents0529\\Task23_xlsx_opener\\converted.json')\n",
    "\n",
    "# 找到空字典键值对\n",
    "def find_empty_values(dict_list):\n",
    "    empty_values_index = {}\n",
    "    for index, sub_dict in enumerate(dict_list):\n",
    "        for key, value in sub_dict.items():\n",
    "            if pd.isna(value) or value == \"\":\n",
    "                if key not in empty_values_index:\n",
    "                    empty_values_index[key] = []\n",
    "                empty_values_index[key].append(index)\n",
    "    \n",
    "    return empty_values_index\n",
    "\n",
    "data=find_empty_values(dict_list)\n",
    "empty_value_path=os.path.join(root_folder,'empty.json')\n",
    "js.write_json(data,empty_value_path)\n",
    "# 实际上这个数据结构就不再有用了，它只是历史数据结构"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 找到含有:分割符的键"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_keys(data):\n",
    "    colon_keys = {}\n",
    "    non_colon_keys = {}\n",
    "\n",
    "    for key, indices in data.items():\n",
    "        if ':' in key:\n",
    "            colon_keys[key] = indices\n",
    "        else:\n",
    "            non_colon_keys[key] = indices\n",
    "    \n",
    "    return colon_keys, non_colon_keys\n",
    "col,non_col=classify_keys(data)\n",
    "#这两个数据结构也只是中间结构\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 为池化任务做准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def process_colon_keys(colon_keys, dict_list):\n",
    "    col_dict_list_dict = {}\n",
    "\n",
    "    for key, indices in colon_keys.items():\n",
    "        parts = key.split(':')\n",
    "        if len(parts) == 3 and parts[0] == \"分类\":\n",
    "            classification_type = parts[1]\n",
    "            classifications = parts[2]\n",
    "\n",
    "            for index in indices:\n",
    "                sub_dict = dict_list[index]\n",
    "                sub_dict[\"classification_type\"] = classification_type\n",
    "                sub_dict[\"classifications\"] = classifications\n",
    "                # 删除值为空的键值对\n",
    "                sub_dict = {k: v for k, v in sub_dict.items() if pd.notna(v) and v != \"\"}\n",
    "\n",
    "                if classification_type not in col_dict_list_dict:\n",
    "                    col_dict_list_dict[classification_type] = []\n",
    "                col_dict_list_dict[classification_type].append(sub_dict)\n",
    "    \n",
    "    return col_dict_list_dict\n",
    "\n",
    "def process_non_colon_keys(non_colon_keys, dict_list):\n",
    "    non_col_dict_list_dict = {}\n",
    "\n",
    "    for key, indices in non_colon_keys.items():\n",
    "        for index in indices:\n",
    "            sub_dict = dict_list[index]\n",
    "            sub_dict[\"generation_type\"] = key\n",
    "            # 删除值为空的键值对\n",
    "            sub_dict = {k: v for k, v in sub_dict.items() if pd.notna(v) and v != \"\"}\n",
    "\n",
    "            if key not in non_col_dict_list_dict:\n",
    "                non_col_dict_list_dict[key] = []\n",
    "            non_col_dict_list_dict[key].append(sub_dict)\n",
    "    \n",
    "    return non_col_dict_list_dict\n",
    "#这两个数据结构是任务池的前数据结构\n",
    "dict_list=js.read_json(r'D:\\Joining\\Joining-Agents0529\\Task23_xlsx_opener\\converted.json')\n",
    "col_dict_list_dict=process_colon_keys(col,dict_list)\n",
    "dict_list=js.read_json(r'D:\\Joining\\Joining-Agents0529\\Task23_xlsx_opener\\converted.json')\n",
    "non_col_dict_list_dict=process_non_colon_keys(non_col,dict_list)\n",
    "col_path=os.path.join(root_folder,\"col_dict_list_dict.json\")\n",
    "non_col_path=os.path.join(root_folder,'non_col_dict_list_dict.json')\n",
    "js.write_json(col_dict_list_dict,col_path)\n",
    "js.write_json(non_col_dict_list_dict,non_col_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 任务池化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all_sub_dicts(col_dict_list_dict, non_col_dict_list_dict):\n",
    "    new_dict_list = []\n",
    "\n",
    "    for classification_type, sub_dicts in col_dict_list_dict.items():\n",
    "        new_dict_list.extend(sub_dicts)\n",
    "\n",
    "    for generation_type, sub_dicts in non_col_dict_list_dict.items():\n",
    "        new_dict_list.extend(sub_dicts)\n",
    "    \n",
    "    return new_dict_list\n",
    "# 提取所有的sub_dict\n",
    "new_dict_list = extract_all_sub_dicts(col_dict_list_dict, non_col_dict_list_dict)\n",
    "\n",
    "# 打印结果\n",
    "print(\"提取的sub_dict列表:\")\n",
    "print(json.dumps(new_dict_list, ensure_ascii=False, indent=4))\n",
    "\n",
    "# 将结果写入 JSON 文件\n",
    "output_path = os.path.join(root_folder,'new_dict_list.json')\n",
    "js.write_json(new_dict_list, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多线程处理任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "def process_task(sub_dict, timeout=20, max_retries=3):\n",
    "    skip_keys = {\"recog_index\", \"classification_type\", \"classifications\", \"generation_type\"}\n",
    "    prompt = '知道现在有一则如下信息:\\n'\n",
    "    \n",
    "    for k, v in sub_dict.items():\n",
    "        if k not in skip_keys:\n",
    "            term_prompt = str(k) + '是' + str(v) + '\\n'\n",
    "            prompt += term_prompt\n",
    "\n",
    "    def make_request(prompt, key_name):\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                answer = service.ask_once(prompt)\n",
    "                answer_dict = js.parse_dict(answer)\n",
    "                if key_name in answer_dict:\n",
    "                    return answer_dict[key_name]\n",
    "                else:\n",
    "                    raise ValueError(\"返回的字典中缺少期望的键\")\n",
    "            except Exception as e:\n",
    "                if \"429\" in str(e) or 'Throttling.RateQuota' in str(e):\n",
    "                    print(f\"429 或 Throttling.RateQuota 错误 {e}: {key_name}，将在 {10 * (attempt + 1)} 秒后重试... (尝试 {attempt + 1})\")\n",
    "                    time.sleep(10 * (attempt + 1))\n",
    "                else:\n",
    "                    print(f\"处理 {key_name} 时出错: {e}, 尝试 {attempt + 1}\")\n",
    "        return None\n",
    "\n",
    "    if \"classification_type\" in sub_dict and \"classifications\" in sub_dict:\n",
    "        prompt += f'''请你在如下具体分类中选择最合适的一个: {sub_dict['classifications']}。\\n\n",
    "        请按照json dict格式返回，键名必须为 {sub_dict['classification_type']}，例如：\n",
    "        {{ \"{sub_dict['classification_type']}\":\"partition_str\"}}\n",
    "        '''\n",
    "        key_name = sub_dict['classification_type']\n",
    "        result = make_request(prompt, key_name)\n",
    "        if result:\n",
    "            sub_dict[key_name] = result\n",
    "            print(\"success\")\n",
    "            return sub_dict\n",
    "    \n",
    "    elif \"generation_type\" in sub_dict:\n",
    "        prompt += f'''请你依据上述信息回答：{sub_dict['generation_type']}。\\n\n",
    "        请按照json dict格式返回，键名必须为 {sub_dict['generation_type']}，例如：\n",
    "        {{ \"{sub_dict['generation_type']}\":\"generation_answer\"}}'''\n",
    "        key_name = sub_dict['generation_type']\n",
    "        result = make_request(prompt, key_name)\n",
    "        if result:\n",
    "            sub_dict[key_name] = result\n",
    "            print(\"success\")\n",
    "            return sub_dict\n",
    "    print(\"failed\")\n",
    "    return sub_dict\n",
    "\n",
    "def process_all_tasks(new_dict_list, max_workers=60):\n",
    "    results = []\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        future_to_sub_dict = {executor.submit(process_task, sub_dict): sub_dict for sub_dict in new_dict_list}\n",
    "        \n",
    "        for future in as_completed(future_to_sub_dict):\n",
    "            sub_dict = future_to_sub_dict[future]\n",
    "            try:\n",
    "                result = future.result()\n",
    "                results.append(result)\n",
    "            except Exception as e:\n",
    "                print(f\"处理 {sub_dict} 时出错: {e}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "dict_list=process_all_tasks(new_dict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def merge_dicts_by_recog_index(dict_list):\n",
    "    merged_dict = {}\n",
    "    \n",
    "    for sub_dict in dict_list:\n",
    "        recog_index = sub_dict.get('recog_index')\n",
    "        if recog_index not in merged_dict:\n",
    "            merged_dict[recog_index] = sub_dict\n",
    "        else:\n",
    "            for k, v in sub_dict.items():\n",
    "                if k not in merged_dict[recog_index]:\n",
    "                    merged_dict[recog_index][k] = v\n",
    "\n",
    "    # 转换为列表\n",
    "    merged_list = list(merged_dict.values())\n",
    "    return merged_list\n",
    "\n",
    "def filter_keys(dict_list, keys_to_remove):\n",
    "    filtered_list = []\n",
    "\n",
    "    for sub_dict in dict_list:\n",
    "        filtered_dict = {k: v for k, v in sub_dict.items() if k not in keys_to_remove}\n",
    "        filtered_list.append(filtered_dict)\n",
    "    \n",
    "    return filtered_list\n",
    "\n",
    "def save_to_excel(dict_list, file_path):\n",
    "    df = pd.DataFrame(dict_list)\n",
    "    df.to_excel(file_path, index=False)\n",
    "\n",
    "merged_list = merge_dicts_by_recog_index(dict_list)\n",
    "keys_to_remove = {'recog_index', 'classification_type', 'classifications', 'generation_type'}\n",
    "filtered_list = filter_keys(merged_list, keys_to_remove)\n",
    "save_to_excel(filtered_list, 'processed_data.xlsx')\n",
    "\n",
    "print(\"处理后的结果已保存到 processed_data.xlsx\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.11 (Jiaoy)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
